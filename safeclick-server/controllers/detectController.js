const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require('axios');

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Model configuration with fallback
const NVIDIA_MODEL = 'meta/llama-4-maverick-17b-128e-instruct';
const NVIDIA_API_URL = 'https://integrate.api.nvidia.com/v1/chat/completions';
const GEMINI_PRIMARY_MODEL = 'gemini-2.0-flash-exp';
const GEMINI_FALLBACK_MODEL = 'gemini-1.5-flash';

// Helper function to call NVIDIA Llama model
async function callNvidiaModel(prompt) {
    const headers = {
        "Authorization": `Bearer ${process.env.NVIDIA_API_KEY}`,
        "Accept": "application/json",
        "Content-Type": "application/json"
    };

    const payload = {
        "model": NVIDIA_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 512,
        "temperature": 1.00,
        "top_p": 1.00,
        "frequency_penalty": 0.00,
        "presence_penalty": 0.00,
        "stream": false
    };

    const response = await axios.post(NVIDIA_API_URL, payload, { headers });
    return response.data.choices[0].message.content;
}

// Helper function to get Gemini model with fallback
async function getGeminiModel(preferPrimary = true) {
    try {
        if (preferPrimary) {
            console.log(`[MODEL] Attempting to use Gemini primary model: ${GEMINI_PRIMARY_MODEL}`);
            return genAI.getGenerativeModel({ model: GEMINI_PRIMARY_MODEL });
        } else {
            console.log(`[MODEL] Using Gemini fallback model: ${GEMINI_FALLBACK_MODEL}`);
            return genAI.getGenerativeModel({ model: GEMINI_FALLBACK_MODEL });
        }
    } catch (err) {
        console.log(`[MODEL] Error getting Gemini model, using fallback: ${err.message}`);
        return genAI.getGenerativeModel({ model: GEMINI_FALLBACK_MODEL });
    }
}

exports.detectAIText = async (req, res) => {
    const { text } = req.body;
    if (!text) return res.status(400).json({ error: "Text is required" });

    const prompt = `
You are an AI detector. I will give you a piece of text. 
Estimate how much of it is likely generated by an AI like ChatGPT, Gemini, etc.
Just return a number between 0 to 100. No explanation.

Text:
"""${text}"""
`;

    // Try NVIDIA Llama model first (primary)
    try {
        console.log(`[AI-DETECT] Attempting primary model: ${NVIDIA_MODEL}`);
        const response = await callNvidiaModel(prompt);
        const percentage = parseInt(response.match(/\d+/)?.[0] || "0", 10);

        console.log(`[AI-DETECT] Analysis complete using NVIDIA Llama model: ${percentage}%`);

        res.json({
            textPreview: text.slice(0, 100) + "...",
            aiLikelihoodPercent: percentage
        });
        return;
    } catch (err) {
        console.error('[AI-DETECT-ERROR] NVIDIA Llama model failed:', err.message);
    }

    // Fallback to Gemini primary model
    try {
        console.log('[AI-DETECT-FALLBACK] Retrying with Gemini primary model...');
        const model = await getGeminiModel(true);
        const result = await model.generateContent(prompt);
        const response = await result.response.text();
        const percentage = parseInt(response.match(/\d+/)?.[0] || "0", 10);

        console.log(`[AI-DETECT] Analysis complete using Gemini primary model: ${percentage}%`);

        res.json({
            textPreview: text.slice(0, 100) + "...",
            aiLikelihoodPercent: percentage
        });
        return;
    } catch (err) {
        console.error('[AI-DETECT-ERROR] Gemini primary model failed:', err.message);
    }

    // Final fallback to Gemini fallback model
    try {
        console.log('[AI-DETECT-FALLBACK] Retrying with Gemini fallback model...');
        const model = await getGeminiModel(false);
        const result = await model.generateContent(prompt);
        const response = await result.response.text();
        const percentage = parseInt(response.match(/\d+/)?.[0] || "0", 10);

        console.log(`[AI-DETECT] Analysis complete using Gemini fallback model: ${percentage}%`);

        res.json({
            textPreview: text.slice(0, 100) + "...",
            aiLikelihoodPercent: percentage
        });
    } catch (fallbackErr) {
        console.error('[AI-DETECT-FALLBACK-ERROR] All models failed:', fallbackErr.message);
        res.status(500).json({ error: "All AI detection models failed. Please try again later." });
    }
};